str(mydata)
### Expore the data - how may assay warnings?
w <- which(mydata$Assay_Warning == "WARN")
length(w)
warn <- mydata[w,]
## How many QC warnings?
w <- which(mydata$QC_Warning == "WARN")
length(w)
qcwarn <- mydata[w,]
## How many proteins
length(unique(mydata$UniProt)) ## 1463
length(unique(mydata$SampleID)) ## 258
length(unique(mydata$OlinkID)) ## 1472
## Column of each protein data
mydatawide <- pivot_wider(
mydata,
id_cols = SampleID,
names_from = UniProt,
names_prefix = "",
names_sep = "_",
names_glue = NULL,
names_sort = FALSE,
names_repair = "check_unique",
values_from = c(NPX, OlinkID, Assay, MissingFreq, Panel, Panel_Lot_Nr, PlateID, QC_Warning, LOD, Normalization, Assay_Warning),
values_fill = NULL,
values_fn = NULL
)
warnings()
mydatawide <- as.data.frame(as.matrix(mydatawide))
for (i in 2:1463) {
mydatawide[,i] <-  as.numeric(unlist(mydatawide[,i]))
}
rm(list = ls())
###### Exploring Olink ByBandSleeve data and QC
###### Started 14/7/21 by Lucy Goudswaard
library(readxl)
library(tidyr)
## Read in data
#mydata <- read.csv(file = "/Volumes/MRC-IEU-research/projects/wt1/wp1/012/working/data/olink_download_v2/20202265_Timpson_NPX_2021-04-27_V2.csv", header = T, sep = ";")
mydata <- read_excel(path = "/Volumes/MRC-IEU-research/projects/wt1/wp1/012/working/data/olink_download_v2/20202265_Timpson_NPX_2021-04-27_V2.xlsx", sheet = NULL, range = NULL, col_names = T)
setwd("/Volumes/012/working/scripts/Lucy/bybandsleeve_taunton125_olink")
###### Merging full dataset for main analysis
## Packages
library(readxl)
library(tidyr)
library(psych)
library(dplyr)
#source("http://news.mrdwab.com/install_github.R")
#install_github("mrdwab/SOfun")
library(SOfun)
library(lme4)
library(nlme)
#remotes::install_github(repo ='Olink-Proteomics/OlinkRPackage/OlinkAnalyze', ref = "main", build_vignettes = TRUE)
library(OlinkAnalyze)
library(ggplot2)
library(tidyverse)
## Set working directory
# read in parameter file (specified on command line)
source("parameter_files/parameters_for_r.R")
# move to working directory
setwd(working_dir)
### Read in pivot wider dataset with additional cols (not just NPX)
mydatawide <- read.table(paste0(data_intermediate_dir, "olink_data_wide_full.txt"), sep = "\t", header = T)
## Read in data
mydata <- read_excel(paste0(prot_input_dir, "olink_download_v2/20202265_Timpson_NPX_2021-04-27_V2.xlsx"))
### Expore the data - how may assay warnings? Will not remove them for now.
w <- which(mydata$Assay_Warning == "WARN")
length(w) # 90 assay warnings
warn <- mydata[w,]
## How many QC warnings?
w <- which(mydata$QC_Warning == "WARN")
length(w) # 28422 assay warnings
qcwarn <- mydata[w,]
## How many proteins
length(unique(mydata$UniProt)) ## 1463
length(unique(mydata$SampleID)) ## 258
length(unique(mydata$OlinkID)) ## 1472
## Olink functions to explore data
## Plot of sample v NPX and coloured by QC_warning
olink_dist_plot(mydata %>% filter(Panel == 'Cardiometabolic')) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank()) +
scale_fill_manual(values = c('turquoise3', 'red'))
# visualize potential outliers by IQR vs. sample median per panel, example for one panel
olink_qc_plot(mydata %>% filter(Panel == 'Cardiometabolic')) +
scale_color_manual(values = c('turquoise3', 'red'))
## Removing control samples (these were coming out as null after pivot_wider)
Controls <- grepl("CONTROL_SAMPLE", mydata$SampleID)
w <- which(Controls == TRUE)
mydata <- mydata[-w,]
## make data into wide format
mydatawide <- pivot_wider(
mydata,
id_cols = SampleID,
names_from = OlinkID,
names_prefix = "",
names_sep = "_",
names_glue = NULL,
names_sort = FALSE,
names_repair = "unique",
values_from = c(NPX, Assay, MissingFreq, Panel, Panel_Lot_Nr, PlateID, QC_Warning, LOD, Normalization, Assay_Warning),
values_fill = NA,
values_fn = NULL
)
mydatawide <- as.data.frame(as.matrix(mydatawide))
## No columns are lists
for (i in 1:ncol(mydatawide)) {
w <- vector(length = 16094)
w[i] <- is.list(mydatawide[,i])
}
for (i in 2:1473) {
mydatawide[,i] <- as.numeric(mydatawide[,i])
}
pdf("figures/00_Olink_histograms.pdf")
par(mfrow=c(3,2))
for (i in 2:1464) {
DataDescribed = psych::describe(mydatawide[,i])
meanvar<-DataDescribed$mean
medianvar<-DataDescribed$median
minvar<-DataDescribed$min
maxvar<-DataDescribed$max
kurtosisvar<-DataDescribed$kurtosis
skewnessvar<-DataDescribed$skew
N<- nrow(mydatawide) - sum(is.na(mydatawide[,i]))
missingness <- (sum(is.na(mydatawide[,i]))/nrow(mydatawide))*100
a<-density(mydatawide[,i], na.rm=T)
thresholdx<-(maxvar+(maxvar/100))
thresholdy<-min(a$y)+(max(a$y)/4)
hist(mydatawide[,i], col="red",main=(names(mydatawide)[i]),prob=TRUE,xlab="peak area")
lines(density(mydatawide[,i], na.rm = TRUE),col="blue", lwd=2)
text(thresholdx,thresholdy, cex=0.6,
paste("N=", N, "\npercent missing=",
signif(missingness, 3), "\nmin=",
signif(minvar, 3), " \nmax=",
signif(maxvar, 3),
"\nmean=",
signif(meanvar, 3), " \nmedian=", signif(medianvar, 3),
"\nkurt=",
signif(kurtosisvar, 3), " \nskew=",
signif(skewnessvar, 3), sep = ''), pos = 3,xpd = NA)
}
dev.off()
pdf(file = "figures/00_Olink_histograms.pdf", height = 10, width = 7)
par(mfrow=c(3,2))
for (i in 2:1464) {
DataDescribed = psych::describe(mydatawide[,i])
meanvar<-DataDescribed$mean
medianvar<-DataDescribed$median
minvar<-DataDescribed$min
maxvar<-DataDescribed$max
kurtosisvar<-DataDescribed$kurtosis
skewnessvar<-DataDescribed$skew
N<- nrow(mydatawide) - sum(is.na(mydatawide[,i]))
missingness <- (sum(is.na(mydatawide[,i]))/nrow(mydatawide))*100
a<-density(mydatawide[,i], na.rm=T)
thresholdx<-(maxvar+(maxvar/100))
thresholdy<-min(a$y)+(max(a$y)/4)
hist(mydatawide[,i], col="red",main=(names(mydatawide)[i]),prob=TRUE,xlab="peak area")
lines(density(mydatawide[,i], na.rm = TRUE),col="blue", lwd=2)
text(thresholdx,thresholdy, cex=0.6,
paste("N=", N, "\npercent missing=",
signif(missingness, 3), "\nmin=",
signif(minvar, 3), " \nmax=",
signif(maxvar, 3),
"\nmean=",
signif(meanvar, 3), " \nmedian=", signif(medianvar, 3),
"\nkurt=",
signif(kurtosisvar, 3), " \nskew=",
signif(skewnessvar, 3), sep = ''), pos = 3,xpd = NA)
}
dev.off()
pdf(file = paste0(data_output_dir, "figures/00_Olink_histograms.pdf"), height = 10, width = 7)
par(mfrow=c(3,2))
for (i in 2:1464) {
DataDescribed = psych::describe(mydatawide[,i])
meanvar<-DataDescribed$mean
medianvar<-DataDescribed$median
minvar<-DataDescribed$min
maxvar<-DataDescribed$max
kurtosisvar<-DataDescribed$kurtosis
skewnessvar<-DataDescribed$skew
N<- nrow(mydatawide) - sum(is.na(mydatawide[,i]))
missingness <- (sum(is.na(mydatawide[,i]))/nrow(mydatawide))*100
a<-density(mydatawide[,i], na.rm=T)
thresholdx<-(maxvar+(maxvar/100))
thresholdy<-min(a$y)+(max(a$y)/4)
hist(mydatawide[,i], col="red",main=(names(mydatawide)[i]),prob=TRUE,xlab="peak area")
lines(density(mydatawide[,i], na.rm = TRUE),col="blue", lwd=2)
text(thresholdx,thresholdy, cex=0.6,
paste("N=", N, "\npercent missing=",
signif(missingness, 3), "\nmin=",
signif(minvar, 3), " \nmax=",
signif(maxvar, 3),
"\nmean=",
signif(meanvar, 3), " \nmedian=", signif(medianvar, 3),
"\nkurt=",
signif(kurtosisvar, 3), " \nskew=",
signif(skewnessvar, 3), sep = ''), pos = 3,xpd = NA)
}
dev.off()
### Read in pivot wider dataset with additional cols (not just NPX)
mydatawide <- read.table(paste0(data_intermediate_dir, "olink_data_wide_full.txt"), sep = "\t", header = T)
### Read in metaboprep output
qcdata <- read.table(paste0(data_intermediate_dir, "metaboprep_release_2021_10_14/filtered_data/LG_bybandsleeve_2021_10_14_Filtered_metabolite_data.txt"), sep = "\t", header = T)
### Sample info
### Read in sample file - combine analyses
samples <- read.csv(paste0(prot_input_dir, "/clinical/Taunton_pilot_olink_annotated_manifest_2021-01-26.csv"))
View(qcdata)
fulldata <- merge(samples, mydatawide, by.x = "Unique.Sample.ID", by.y = "SampleID")
fulldata_noqc <- merge(samples, mydatawide, by.x = "Unique.Sample.ID", by.y = "SampleID")
fulldata <- merge(fulldata, qcdata, by = "SampleID")
qcdata[,1] <- rownames(qcdata)
colnames(qcdata[,1]) <- "SampleID"
View(qcdata)
### Read in metaboprep output
qcdata <- read.table(paste0(data_intermediate_dir, "metaboprep_release_2021_10_14/filtered_data/LG_bybandsleeve_2021_10_14_Filtered_metabolite_data.txt"), sep = "\t", col.names=T, row.names=F)
### Read in metaboprep output
qcdata <- read.table(paste0(data_intermediate_dir, "metaboprep_release_2021_10_14/filtered_data/LG_bybandsleeve_2021_10_14_Filtered_metabolite_data.txt"), sep = "\t", header=T)
IDs <- rownames(qcdata)
qcdata <- cbind(qcdata, IDs)
colnames(qcdata[,1]) <- "SampleID"
View(qcdata)
names(qcdata)[1] <- "SampleID"
View(qcdata)
### Read in metaboprep output
qcdata <- read.table(paste0(data_intermediate_dir, "metaboprep_release_2021_10_14/filtered_data/LG_bybandsleeve_2021_10_14_Filtered_metabolite_data.txt"), sep = "\t", header=T)
IDs <- as.matrix(rownames(qcdata))
qcdata <- cbind(qcdata, IDs)
View(qcdata)
### Read in metaboprep output
qcdata <- read.table(paste0(data_intermediate_dir, "metaboprep_release_2021_10_14/filtered_data/LG_bybandsleeve_2021_10_14_Filtered_metabolite_data.txt"), sep = "\t", header=T, row.names = F)
rownames(qcdata) <- NULL
qcdata <- cbind(IDs, qcdata)
View(qcdata)
names(qcdata)[1] <- "SampleID"
View(mydatawide)
### Sample info
### Read in sample file - combine dataframes
samples <- read.csv(paste0(prot_input_dir, "/clinical/Taunton_pilot_olink_annotated_manifest_2021-01-26.csv"))
mydata <- merge(samples, qcdata, by.x = "Unique.Sample.ID", by.y = "SampleID")
colnames(samples)
colnames(qcdata)
View(samples)
View(qcdata)
library(readxl)
library(tidyr)
library(psych)
library(dplyr)
#source("http://news.mrdwab.com/install_github.R")
#install_github("mrdwab/SOfun")
library(SOfun)
library(lme4)
library(nlme)
#remotes::install_github(repo ='Olink-Proteomics/OlinkRPackage/OlinkAnalyze', ref = "main", build_vignettes = TRUE)
library(OlinkAnalyze)
library(ggplot2)
library(tidyverse)
## Make IDs lower case
samples$Unique.Sample.ID <- tolower(samples$Unique.Sample.ID)
samples$Unique.Sample.ID <- gsub("-", " ", samples$Unique.Sample.ID )
View(samples)
### Sample info
### Read in sample file - combine dataframes
samples <- read.csv(paste0(prot_input_dir, "/clinical/Taunton_pilot_olink_annotated_manifest_2021-01-26.csv"))
## Make IDs lower case
samples$Unique.Sample.ID <- tolower(samples$Unique.Sample.ID)
samples$Unique.Sample.ID <- gsub("-", "", samples$Unique.Sample.ID )
View(samples)
## Merge sample info with QC'd Olink data
mydata <- merge(samples, qcdata, by.x = "Unique.Sample.ID", by.y = "SampleID")
View(mydata)
w <- which(mydata$timepoint == "36 months")
mydata$timepoint[w] <- "1"
w <- which(mydata$timepoint == "Baseline")
mydata$timepoint[w] <- "0"
mydata$timepoint <- as.numeric(mydata$timepoint)
mydata$study_id <- as.factor(mydata$study_id)
View(mydata)
table(mydata$studyid)
table(mydata$study_id)
## Read in basic phenotype variables
phenotypes <- read.csv(paste0(prot_input_dir, "/clinical/Taunton_pilot_olink_annotated_manifest_2021-01-26.csv"))
View(phenotypes)
## Read in basic phenotype variables
phenotypes <- read.csv(paste0(prot_input_dir, "/clinical/BBS-2021-09-06_taunton125_analysis_extract_2021-10-07.csv"))
View(phenotypes)
phenotypes$study_id <- tolower(phenotypes$study_id)
phenotypes$study_id <- gsub("-", "", phenotypes$study_id )
View(mydata)
View(mydata)
## Merge
mydata <- merge(phenotypes, mydata, by.x = "sample_id", by.y = "Unique.Sample.ID")
phenotypes$sample_id <- tolower(phenotypes$sample_id)
phenotypes$sample_id <- gsub("-", "", phenotypes$sample_id )
## Merge
mydata <- merge(phenotypes, mydata, by.x = "sample_id", by.y = "Unique.Sample.ID", all.y = TRUE)
colnames(phenotypes)
colnames(mydata)
## Merge
mydata <- merge(phenotypes, mydata, by = "sample_id", all.y = TRUE)
## Merge sample info with QC'd Olink data
mydata <- merge(samples, qcdata, by.x = "Unique.Sample.ID", by.y = "SampleID")
## Read in basic phenotype variables
phenotypes <- read.csv(paste0(prot_input_dir, "/clinical/BBS-2021-09-06_taunton125_analysis_extract_2021-10-07.csv"))
phenotypes$sample_id <- tolower(phenotypes$sample_id)
phenotypes$sample_id <- gsub("-", "", phenotypes$sample_id )
## Merge
mydata <- merge(phenotypes, mydata, by = "sample_id", all.y = TRUE)
mydatawide <- read.table(paste0(data_intermediate_dir, "olink_data_wide_full.txt"), sep = "\t", header = T)
### Read in metaboprep output and format to give SampleID in first row followed by protein levels
qcdata <- read.table(paste0(data_intermediate_dir, "metaboprep_release_2021_10_14/filtered_data/LG_bybandsleeve_2021_10_14_Filtered_metabolite_data.txt"), sep = "\t", header=T)
IDs <- as.matrix(rownames(qcdata))
rownames(qcdata) <- NULL
qcdata <- cbind(IDs, qcdata)
names(qcdata)[1] <- "SampleID"
### Sample info
### Read in sample file - combine dataframes
samples <- read.csv(paste0(prot_input_dir, "/clinical/Taunton_pilot_olink_annotated_manifest_2021-01-26.csv"))
## Make IDs lower case
samples$Unique.Sample.ID <- tolower(samples$Unique.Sample.ID)
samples$Unique.Sample.ID <- gsub("-", "", samples$Unique.Sample.ID )
## Merge sample info with QC'd Olink data
mydata <- merge(samples, qcdata, by.x = "Unique.Sample.ID", by.y = "SampleID")
## Read in basic phenotype variables
phenotypes <- read.csv(paste0(prot_input_dir, "/clinical/BBS-2021-09-06_taunton125_analysis_extract_2021-10-07.csv"))
phenotypes$sample_id <- tolower(phenotypes$sample_id)
phenotypes$sample_id <- gsub("-", "", phenotypes$sample_id )
## Merge
mydata <- merge(phenotypes, mydata, by = "sample_id", all.y = TRUE)
colnames(phenotypes)
colnames(mydata[,1:50])
## Merge
mydata2 <- merge(phenotypes, mydata, by.x = "sample_id", by.y = "Unique.Sample.ID", all.y = TRUE)
## Merge
mydata <- merge(phenotypes, mydata, by.x = "sample_id", by.y = "Unique.Sample.ID", all.y = TRUE)
colnames(mydata[,1:100])
hist(mydata$Patient.Weight)
## Make a dataframe of baseline and 36 months
w <- which(mydata$timepoint == "36 months")
mydata$timepoint[w] <- "1"
w <- which(mydata$timepoint == "Baseline")
mydata$timepoint[w] <- "0"
mydata$timepoint <- as.numeric(mydata$timepoint)
?boxplot
?geom_boxplot
ggplot(mydata, aes(x=as.factor(timepoint), y=Patient.Weight)) +
geom_boxplot(fill="slateblue", alpha=0.2) +
xlab("cyl")
mydata <- merge(phenotypes, mydata, by.x = "sample_id", by.y = "Unique.Sample.ID", all.y = TRUE)
weightbox <- ggplot(mydata, aes(x=as.factor(timepoint), y=Patient.Weight)) +
geom_boxplot(fill="slateblue", alpha=0.2) +
xlab("Timepoint")
mydata <- merge(samples, qcdata, by.x = "Unique.Sample.ID", by.y = "SampleID")
## Read in basic phenotype variables
phenotypes <- read.csv(paste0(prot_input_dir, "/clinical/BBS-2021-09-06_taunton125_analysis_extract_2021-10-07.csv"))
phenotypes$sample_id <- tolower(phenotypes$sample_id)
phenotypes$sample_id <- gsub("-", "", phenotypes$sample_id )
## Merge
mydata <- merge(phenotypes, mydata, by.x = "sample_id", by.y = "Unique.Sample.ID", all.y = TRUE)
weightbox <- ggplot(mydata, aes(x=as.factor(timepoint), y=Patient.Weight)) +
geom_boxplot(fill="slateblue", alpha=0.2) +
xlab("Timepoint")
weightbox
## Paired ttest to compare weight
t.test( endpoint$Patient.Weight, baseline$Patient.Weight, paired = TRUE)
pairdata <- mydata[order(mydata$study_id),]
w <- which(pairdata$timepoint == 0)
baseline <- pairdata[w,]
w <- which(pairdata$timepoint == 1)
endpoint <- pairdata[w,]
t.test( endpoint$NPX_OID20245, baseline$NPX_OID20245, paired = TRUE)
t.test( endpoint$oid20245, baseline$oid20245, paired = TRUE)
w <- which(mydata$timepoint == "36 months")
mydata$timepoint[w] <- "1"
w <- which(mydata$timepoint == "Baseline")
mydata$timepoint[w] <- "0"
mydata$timepoint <- as.numeric(mydata$timepoint)
## Make study ID factor (this ID identifies individual, combine with time point info to determine
## for each individual which is baseline and 36 months)
mydata$study_id <- as.factor(mydata$study_id)
### Compare protein across timepoints - protein ~ time + subject
lmerfun <-  lmer(formula = NPX_OID20837 ~ timepoint + timepoint * (1|study_id), data=mydata)
lmerfunx <-  lmer(formula = NPX_OID20245 ~ timepoint + timepoint * (1|study_id), data=mydata)
### Paired t test - split baseline and endpoint to separate dataframes for ttest
pairdata <- mydata[order(mydata$study_id),]
w <- which(pairdata$timepoint == 0)
baseline <- pairdata[w,]
w <- which(pairdata$timepoint == 1)
endpoint <- pairdata[w,]
t.test( endpoint$oid20245, baseline$oid20245, paired = TRUE)
t.test(na.omit( endpoint$oid20245, baseline$oid20245, paired = TRUE))
## Paired ttest to compare weight
t.test(na.omit( endpoint$Patient.Weight, baseline$Patient.Weight, paired = TRUE))
## Paired ttest to compare weight
weight <- t.test(na.omit( endpoint$Patient.Weight, baseline$Patient.Weight, paired = TRUE))
summary(weight)
weight
?t.test
## Paired ttest to compare weight
weight <- t.test(na.omit( Patient.Weight ~ timepoint, data = mydata, paired = TRUE))
View(baseline)
View(baseline)
colnames(mydata)
install.packages("gtools")
library(gtools)
### Paired t test - split baseline and endpoint to separate dataframes for ttest
mydata <- mydata[order(mydata$study_id),]
View(mydata)
## Keep IDs mentioned twice
w <- which(unique(mydata$study_id))
## Keep IDs mentioned twice
w <- unique(mydata$study_id))
## Keep IDs mentioned twice
w <- unique(mydata$study_id)
## Keep IDs mentioned twice
#w <- unique(mydata$study_id)
w <- which(unique(mydata["study_id"]))
## Keep IDs mentioned twice
#w <- unique(mydata$study_id)
length(unique(mydata["study_id"]))
table(mydata$study_id)
dim(mydata)
sum(is.na(mydata$study_id))
w <- which(mydata$study_id == "TAU0244")
mydata <- mydata[-w,]
## Separate dataframes of timepoints
w <- which(pairdata$timepoint == 0)
baseline <- pairdata[w,]
w <- which(pairdata$timepoint == 1)
endpoint <- pairdata[w,]
## T-test example
t.test(na.omit( endpoint$oid20245, baseline$oid20245, paired = TRUE))
## Paired ttest to compare weight - get same order
weight <- t.test(na.omit( endpoint$Patient.Weight, baseline$Patient.Weight, paired = TRUE))
View(endpoint)
View(baseline)
weight
## Separate dataframes of timepoints
w <- which(pairdata$timepoint == 0)
baseline <- pairdata[w,]
w <- which(pairdata$timepoint == 1)
endpoint <- pairdata[w,]
w <- which(mydata$timepoint == 0)
baseline <- mydata[w,]
w <- which(mydata$timepoint == 1)
endpoint <- mydata[w,]
## T-test example
t.test(na.omit( endpoint$oid20245, baseline$oid20245, paired = TRUE))
mydatawide <- read.table(paste0(data_intermediate_dir, "olink_data_wide_full.txt"), sep = "\t", header = T)
### Read in metaboprep output and format to give SampleID in first row followed by protein levels
qcdata <- read.table(paste0(data_intermediate_dir, "metaboprep_release_2021_10_14/filtered_data/LG_bybandsleeve_2021_10_14_Filtered_metabolite_data.txt"), sep = "\t", header=T)
IDs <- as.matrix(rownames(qcdata))
rownames(qcdata) <- NULL
qcdata <- cbind(IDs, qcdata)
names(qcdata)[1] <- "SampleID"
### Sample info
### Read in sample file - combine dataframes
samples <- read.csv(paste0(prot_input_dir, "/clinical/Taunton_pilot_olink_annotated_manifest_2021-01-26.csv"))
## Make IDs lower case
samples$Unique.Sample.ID <- tolower(samples$Unique.Sample.ID)
samples$Unique.Sample.ID <- gsub("-", "", samples$Unique.Sample.ID )
## Merge sample info with QC'd Olink data
mydata <- merge(samples, qcdata, by.x = "Unique.Sample.ID", by.y = "SampleID")
## Read in basic phenotype variables
phenotypes <- read.csv(paste0(prot_input_dir, "/clinical/BBS-2021-09-06_taunton125_analysis_extract_2021-10-07.csv"))
phenotypes$sample_id <- tolower(phenotypes$sample_id)
phenotypes$sample_id <- gsub("-", "", phenotypes$sample_id )
## Merge
mydata <- merge(phenotypes, mydata, by.x = "sample_id", by.y = "Unique.Sample.ID", all.y = TRUE)
#boxplot
weightbox <- ggplot(mydata, aes(x=as.factor(timepoint), y=Patient.Weight)) +
geom_boxplot(fill="slateblue", alpha=0.2) +
xlab("Timepoint") + ylab(Weight (kgs))
## Make study ID factor (this ID identifies individual, combine with time point info to determine
## for each individual which is baseline and 36 months)
mydata <- mydata[order(mydata[, "study_id"]),]
mydata$study_id <- as.factor(mydata$study_id)
## Make a dataframe of baseline and 36 months
w <- which(mydata$timepoint == "36 months")
mydata$timepoint[w] <- "1"
w <- which(mydata$timepoint == "Baseline")
mydata$timepoint[w] <- "0"
mydata$timepoint <- as.numeric(mydata$timepoint)
table(mydata$timepoint)
table(mydata$study_id)
rm(list = ls())
wordcountaddin:::text_stats()
wordcountaddin:::text_stats()
wordcountaddin:::text_stats()
wordcountaddin:::text_stats()
wordcountaddin:::readability()
wordcountaddin:::text_stats()
wordcountaddin::word_count("*.Rmd"))
wordcountaddin::word_count("*.Rmd")
setwd("~/OneDrive - University of Bristol/PhD/Main project/Thesis/index")
wordcountaddin::word_count("*.Rmd")
wordcountaddin::word_count(c('01-chap1.Rmd', '02-chap2.Rmd','03-chap3.Rmd', '04-chap4.Rmd','05-chap5.Rmd','06-chap6.Rmd','07-chap7.Rmd', '08-chap8.Rmd'))
wordcountaddin::word_count('01-chap1.Rmd'')
)
)
x
wordcountaddin::word_count('01-chap1.Rmd')
wordcountaddin::word_count('02-chap2.Rmd')
wordcountaddin::word_count('03-chap3.Rmd')
wordcountaddin::word_count('04-chap4.Rmd')
wordcountaddin::word_count('05-chap5.Rmd')
wordcountaddin::word_count('06-chap6.Rmd')
wordcountaddin::word_count('07-chap7.Rmd')
wordcountaddin::word_count('08-chap8.Rmd')
wordcountaddin:::text_stats()
wordcountaddin:::text_stats()
1463 + 3164 + 3513 + 4287 + 3324 + 4676 + 3157 +2681 + 1552
